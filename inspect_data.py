import os
import glob
import pandas as pd
import json
import pyarrow.parquet as pq

# é…ç½®æ˜¾ç¤ºå®½åº¦
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
pd.set_option('display.max_colwidth', 150)
pd.set_option('display.width', 200)

def print_separator(title):
    print("\n" + "="*80)
    print(f" {title}")
    print("="*80)

def inspect_parquet(file_path, rows=2):
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return

    try:
        # åªè¯»å–å‰å‡ è¡Œ
        df = pd.read_parquet(file_path).head(rows)
        print(f"âœ… æ–‡ä»¶: {os.path.basename(file_path)}")
        print(f"   è·¯å¾„: {file_path}")
        print(f"   åˆ—å: {list(df.columns)}")
        print(f"   æ ·ä¾‹æ•°æ® (Top {rows}):")
        print(df.to_string(index=False))
        
        # å°è¯•è§£æå¤æ‚åˆ—
        if 'messages' in df.columns and len(df) > 0:
            print("\n   ğŸ” æ·±åº¦è§£æ 'messages' åˆ—çš„ç¬¬ä¸€æ¡:")
            msg_content = df.iloc[0]['messages']
            if isinstance(msg_content, str):
                try:
                    print(json.dumps(json.loads(msg_content), indent=2, ensure_ascii=False)[:500] + " ...")
                except:
                    print(msg_content[:500])
            else:
                # å¯èƒ½æ˜¯ array
                print(msg_content)
        
        if 'segments' in df.columns and len(df) > 0:
            print("\n   ğŸ” æ·±åº¦è§£æ 'segments' åˆ—çš„ç¬¬ä¸€æ¡:")
            seg_content = df.iloc[0]['segments']
            print(seg_content)

    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥: {e}")

# ================= 1. æ£€æŸ¥åŸå§‹æ•°æ® (Raw Data) =================
print_separator("Phase 0: åŸå§‹æ•°æ® (Raw Data)")

# 1.1 é€šç”¨æ–‡æœ¬
general_files = glob.glob("raw_data/general_text/pretrain/*.parquet")
if general_files:
    print(f"ğŸ“š å‘ç°é€šç”¨é¢„è®­ç»ƒæ•°æ®: {len(general_files)} ä¸ªæ–‡ä»¶")
    inspect_parquet(general_files[0])
else:
    print("âš ï¸ æœªå‘ç°é€šç”¨é¢„è®­ç»ƒæ•°æ® (raw_data/general_text/pretrain)")

# 1.2 æ¨èæ•°æ®
rec_file = "raw_data/onerec_data/onerec_bench_release.parquet"
if os.path.exists(rec_file):
    print(f"\nğŸ“š å‘ç°æ¨èä¸šåŠ¡æ•°æ®")
    inspect_parquet(rec_file)
else:
    print(f"\nâš ï¸ æœªå‘ç°æ¨èä¸šåŠ¡æ•°æ® ({rec_file})")

# 1.3 æ˜ å°„è¡¨
mapping_file = "raw_data/onerec_data/video_ad_pid2sid.parquet"
if os.path.exists(mapping_file):
    print(f"\nğŸ“š å‘ç° ID æ˜ å°„è¡¨")
    inspect_parquet(mapping_file)

# ================= 2. æ£€æŸ¥å¤„ç†åçš„ä¸­é—´æ•°æ® (Processed Output) =================
print_separator("Phase 1.1: å¤„ç†åçš„æ¨èæ•°æ® (output/*.parquet)")
output_files = glob.glob("output/*.parquet")
if output_files:
    print(f"ğŸ“š å‘ç°å¤„ç†åçš„æ–‡ä»¶: {len(output_files)} ä¸ª")
    # æ‰¾ä¸€ä¸ª SFT çš„å’Œä¸€ä¸ª Pretrain çš„çœ‹
    sft_files = [f for f in output_files if 'sft' in f]
    pretrain_files = [f for f in output_files if 'pretrain' in f]
    
    if sft_files:
        print("\n--- SFT æ ¼å¼æ ·ä¾‹ ---")
        inspect_parquet(sft_files[0])
    if pretrain_files:
        print("\n--- Pretrain æ ¼å¼æ ·ä¾‹ ---")
        inspect_parquet(pretrain_files[0])
else:
    print("âš ï¸ output/ ç›®å½•ä¸‹æ²¡æœ‰ Parquet æ–‡ä»¶ (å°šæœªè¿è¡Œ data/onerec_data/run.sh ?)")

# ================= 3. æ£€æŸ¥åˆ†ç‰‡æ•°æ® (Sharded Split Data) =================
print_separator("Phase 3: æœ€ç»ˆåˆ†ç‰‡æ•°æ® (output/split_data_*")
split_dirs = glob.glob("output/split_data_*")
if split_dirs:
    for d in split_dirs:
        print(f"\nğŸ“‚ ç›®å½•: {d}")
        files = glob.glob(os.path.join(d, "*.parquet"))
        print(f"   åŒ…å«æ–‡ä»¶æ•°: {len(files)}")
        if files:
            inspect_parquet(files[0], rows=1)
else:
    print("âš ï¸ æœªå‘ç°åˆ†ç‰‡æ•°æ®ç›®å½• (å°šæœªè¿è¡Œ prepare_*.sh ?)")

print("\n" + "="*80)
print("æ£€æŸ¥ç»“æŸ")
