#!/bin/bash

# ================= é…ç½®åŒºåŸŸ =================
# æŒ‡å®šä½¿ç”¨çš„ GPU ç¼–å·
export CUDA_VISIBLE_DEVICES=2,3,4,5

# æ¨¡å‹è·¯å¾„ (åˆšåˆšç¡®è®¤è¿‡çš„è·¯å¾„)
MODEL_DIR="/zhdd/home/lkzhang/vscode/evaluate_exp/OpenOneRec/data/code/onerec_pretrain/hf_models/Qwen3-0.6B_itemic"

# è¾“å‡ºè·¯å¾„ (æ”¹ä¸ºæ‚¨çš„å·¥ä½œç›®å½•)
OUTPUT_DIR="/zhdd/home/lkzhang/vscode/evaluate_exp/OpenOneRec/output/stg1_opt"

# æ•°æ®é…ç½® (æ³¨æ„ï¼šè¯·ç¡®è®¤æ­¤ JSON é‡Œçš„ sources è·¯å¾„æ˜¯å¦æ­£ç¡®)
DATASET_CONFIG="examples/dataset_config/pretrain.json"

# ===========================================

mkdir -p $OUTPUT_DIR
mkdir -p /tmp/_wids_cache

export PYTHONPATH=$PWD:$PYTHONPATH

# Disable proxy for localhost to avoid torch.distributed connection issues
export no_proxy=localhost,127.0.0.1,::1
export NO_PROXY=localhost,127.0.0.1,::1

# è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒçš„ç¯å¢ƒå˜é‡
export MASTER_ADDR=localhost
export MASTER_PORT=29500

echo "ğŸš€ å¼€å§‹ Stage 1 é¢„è®­ç»ƒ..."
echo "ğŸ“ æ¨¡å‹: $MODEL_DIR"
echo "ğŸ“ è¾“å‡º: $OUTPUT_DIR"

# ä½¿ç”¨ torchrun å¯åŠ¨
# nproc_per_node = 4 (å› ä¸ºæŒ‡å®šäº† 4 å¼ å¡: 2,3,4,5)
# Unset LD_PRELOAD to disable proxychains for torchrun
unset LD_PRELOAD
/home/lkzhang/miniconda3/envs/openonerec/bin/torchrun --nproc_per_node=4 \
    --master_port=$MASTER_PORT \
    recipes/train_qwen3.py \
    --model_dir $MODEL_DIR \
    --output_dir $OUTPUT_DIR \
    --dataset_config $DATASET_CONFIG \
    --freeze_llm \
    --use_tie_weights \
    --start_optimize_embedding_index 151669 \
    --model_class Qwen3ForCausalLM \
    --monitor_datasource_loss \
    --monitor_datasource_cnt \
    --max_length 32768 \
    --learning_rate 2e-4 \
    --min_lr 1e-4 \
    --weight_decay 0.1 \
    --lr_scheduler_type cosine \
    --num_warmup_steps 200 \
    --num_training_steps 2000 \
    --save_checkpoint_per_step 50 \
    --minibatch_size 4096 \
    --logging_per_step 5 \
    --use_fp32_weight \
    --seed 19260817 \
    --enable_gradient_checkpointing \
    --use_chunked_loss_computer
